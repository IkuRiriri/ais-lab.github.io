---
title: iSpace
author: Kakeru Minesaki
lang: jp
tags:
  - iSpace
---

{% case site.lang %}
{% when 'en' %}
# Intelligent Space

{% capture col1 %}
{%
  include figure.html
  image="/images/ispace/01_ispace.png"
  caption="Overview of iSpace"
  width="80%"
%}
{% endcapture %}
{% capture col2 %}
The Intelligent Space (iSpace) is a space that can analyze human behavior through computer vision and present user-centric information, and autonomously control robots as users intend. This study aims to support humans and robots to enhance their performances informatively and physically. To develop such a smart space, iSpace needs to know “when, where, who did what”. Therefore, iSpace is a research theme that requires various fundamental technologies and functions, and it encompasses a wide range of subtopics.
{% endcapture %}

{%
  include cols.html
  col1=col1
  col2=col2
%}

## iSpace Coding
To achieve iSpace, it is essential to create environments that are convenient and comfortable for users. However, the functions required in such spaces vary from user to user. This is where the concept of “**iSpace coding**" becomes important—a technology that allows users to freely define the behaviors of robots and appliances according to their individual needs.
iSpace coding enables anyone to easily configure the functions of the space using intuitive input methods, such as dedicated interfaces or natural language. As a result, even general users can freely build iSpace tailored to their preferences.

{% include responsive-file.html type="video" url="/images/ispace/02_ispace_coding1.mp4" caption="Implementation of Spatial Functions Defined by Virtual Objects (Areas and Lines) Through a Dedicated Interface" width="70%" %}

{% include responsive-file.html type="video" url="/images/ispace/03_ispace_coding2.mp4" caption="Implementation of Spatial Function Definition Using Natural Language" width="70%" %}

## Real-time Person Re-identification in Multi-Camera Environment
We have developed a system capable of detecting and tracking people across different cameras in a room. For each camera, deep learning is used to detect the position and skeleton pose of each person.
{%
  include figure.html
  image="/images/ispace/04_Re-ID.jpg"
  caption="On the left, each person is detected (bounding boxes) along with the corresponding skeleton pose. Then, the position of each person is mapped from the camera view to the global map of the room shown on the right."
  width="90%"
%}

Then, our system perform multi-camera tracking by generating a single ID number for each person across different cameras. All of these are performed in real-time speed using a single consumer GPU, making it suitable to be deployed for applications.

{% include responsive-file.html type="video" url="/images/ispace/05_Re-ID.mp4" caption="A demo video of our system." width="90%" %}

## Development of an information-sharing platform

{% capture col1 %}
This research focuses on developing a platform that integrates data from multiple cameras installed in iSpace into a unified map, enabling information sharing with robots and various applications.

The platform accumulates and visualizes the positions and movement histories of people within the space, allowing for real-time human tracking. This makes it possible to provide context-aware services based on behavior patterns—for example, offering assistance only to individuals who have been working in a specific area for an extended period.
{% endcapture %}
{% capture col2 %}
{%
  include figure.html
  image="/images/ispace/06_information_sharing.gif"
  caption="Demo Video of Multi-Person Tracking Using Multiple Cameras"
  width="90%"
%}
{% endcapture %}

{%
  include cols.html
  col1=col1
  col2=col2
%}

## Detection of Left-Behind Objects
This study aims to develop a system to prevent forgotten items. Forgetting things is a common issue in daily life, often causing emotional distress, financial loss, and anxiety. Many people especially feel uneasy when leaving for work or school, wondering if they have forgotten something.

{% capture col1 %}
{%
  include figure.html
  image="/images/ispace/07_left_behind_objects1.png"
  caption="The Scene Inside the Space"
  width="80%"
%}
{% endcapture %}
{% capture col2 %}
{%
  include figure.html
  image="/images/ispace/08_left_behind_objects2.png"
  caption="Log Display Interface"
  width="80%"
%}
{% endcapture %}

{%
  include cols.html
  col1=col1
  col2=col2
%}

Our system detects forgotten items by tracking a person’s interaction with objects—such as touching, moving, or leaving them—using cameras to understand the final location of each item. It also logs the type of object and the person who handled it, enabling timely notifications to the user when necessary. In the future, we aim to incorporate the user's schedule to predict and notify them in advance about items they are likely to forget, as well as provide intuitive alerts. This technology also holds potential for applications in other fields, such as caregiving and security.

## Interaction System Using Mobile Devices
In this study, we propose an interaction system that enables users to intuitively interact with devices in iSpace using mobile devices such as smartphones. When the user points their smartphone camera at a device, a corresponding control interface is displayed on the screen, allowing direct operation.

A previously proposed system called R-Fii required pre-trained data to operate devices, and it faced challenges in distinguishing between multiple instances of the same type of object.

To address this issue, our system incorporates "YOLO-World," a state-of-the-art object recognition model that works without the need for pre-training on specific objects. By leveraging the smartphone camera’s positional and orientation (pose) information, the system can accurately differentiate between objects of the same type.

{% capture col1 %}
{%
  include figure.html
  image="/images/ispace/10_mobile1.png"
  caption="Overview of the Interaction System"
  width="80%"
%}
{% endcapture %}
{% capture col2 %}
{%
  include figure.html
  image="/images/ispace/11_mobile2.png"
  caption="Flow of the Interaction System"
  width="80%"
%}
{% endcapture %}

{%
  include cols.html
  col1=col1
  col2=col2
%}

{% include responsive-file.html type="video" url="/images/ispace/12_mobile3.mp4" caption="Demo Video of the Interaction System" width="70%" %}

## Furniture Repositioning System
As part of research on intelligent space, this study focuses on developing a system that optimizes the arrangement of indoor objects according to the current situation. During everyday use, furniture in a room may shift from its intended position. This research specifically targets chairs, which tend to be moved frequently, with the goal of developing a system that can correct their positions in real time.

{% include responsive-file.html type="video" url="/images/ispace/13_furniture.mp4" caption="Scene of Moving a Chair" width="70%" %}

To achieve this, the system uses cameras installed in the space to detect the current positions of chairs and compares them with their predefined locations to determine whether any displacement has occurred. When a deviation is detected, a robot receives the positional information of the chair and returns it to its original position.

{% when 'jp' %}
# 空間知能化（Intelligent Space）

{% capture col1 %}
{%
  include figure.html
  image="/images/ispace/01_ispace.png"
  caption="知能化空間の概要"
  width="80%"
%}
{% endcapture %}
{% capture col2 %}
空間知能化とは、空間を賢くし、人間を支援する研究です。人になるべく負担をかけず、環境側にセンサ、ネットワーク、人工知能など様々なデバイスを分散配置することで空間内の人間を支援することを目指しています。このようなシステムを開発するプロセスを空間知能化、それで出来上がる賢い空間を知能化空間と呼んでいます。空間知能化は様々な要素技術及び機能が必要とされる研究テーマで、様々な小テーマがあります。
{% endcapture %}

{%
  include cols.html
  col1=col1
  col2=col2
%}

## 空間コーディング
知能化空間の実現には、ユーザにとって便利で快適な空間を構築することが求められます。しかし、その空間に求められる機能はユーザごとに異なります。そこで必要となるのが、ユーザ自身の要望に応じて、ロボットや家電のふるまいを自由に定義できる「**空間コーディング**」という技術です。
空間コーディングでは、専用のインタフェースや自然言語といった直感的な入力方法を用いることで、誰でも簡単に空間の機能を設定することができます。これにより、一般的なユーザでも、自分に合った知能化空間を自由に構築できるようになります。

{% include responsive-file.html type="video" url="/images/ispace/02_ispace_coding1.mp4" caption="専用のインタフェースから仮想的なオブジェクト（エリア、ライン）を用いて空間の機能を定義した時の実装" width="70%" %}

{% include responsive-file.html type="video" url="/images/ispace/03_ispace_coding2.mp4" caption="自然言語で空間機能を定義した時の実装" width="70%" %}

## マルチカメラ環境におけるリアルタイム人物再識別
私たちは、部屋内の複数のカメラにまたがって人を検出し追跡できるシステムを開発しました。各カメラごとに、ディープラーニングを用いて人物の位置と骨格姿勢を検出します。
{%
  include figure.html
  image="/images/ispace/04_Re-ID.jpg"
  caption="左側では、それぞれの人物がバウンディングボックスとともに検出され、対応する骨格姿勢も推定されます。その後、各人物の位置がカメラ視点から右側に示された部屋のグローバルマップへとマッピングされます。"
  width="90%"
%}

その後、システムは異なるカメラ間で同一人物に対して共通のID番号を生成することでマルチカメラトラッキングを実現します。これらすべては、一般的なコンシューマ向けGPUを用いてリアルタイムで処理されるため、さまざまなアプリケーションへの導入に適しています。

{% include responsive-file.html type="video" url="/images/ispace/05_Re-ID.mp4" caption="デモ動画" width="90%" %}

## 情報共有プラットフォームの開発

{% capture col1 %}
本研究では、知能化空間に配置した複数のカメラから得られるデータを一つの地図上に統合し、ロボットや各種アプリケーションと情報を共有できるプラットフォームの開発を行っています。

本プラットフォームは、空間内の人の位置や移動履歴を蓄積・可視化し、リアルタイムでの人物トラッキングを可能にします。これにより、例えば長時間特定の場所に滞在して作業している人物に対してのみサービスを提供するなど、滞在時間や行動パターンに基づいた適切なサービスの提供が可能になります。
{% endcapture %}
{% capture col2 %}
{%
  include figure.html
  image="/images/ispace/06_information_sharing.gif"
  caption="複数カメラを用いた複数人トラッキング"
  width="90%"
%}
{% endcapture %}

{%
  include cols.html
  col1=col1
  col2=col2
%}

## 忘れ物検出
本研究では、忘れ物防止機能の実現を目指しています。忘れ物は日常生活で頻繁に発生し、精神的・金銭的な損失や不安の原因となります。特に、出勤や通学時に「何かを忘れていないか」と不安に感じる人は多いです。

{% capture col1 %}
{%
  include figure.html
  image="/images/ispace/07_left_behind_objects1.png"
  caption="空間内の様子"
  width="80%"
%}
{% endcapture %}
{% capture col2 %}
{%
  include figure.html
  image="/images/ispace/08_left_behind_objects2.png"
  caption="ログ表示インタフェース"
  width="80%"
%}
{% endcapture %}

{%
  include cols.html
  col1=col1
  col2=col2
%}

人が物体に接触し、移動・放置する一連の行動をカメラでトラッキングし、最終的な物体の位置を把握することで忘れ物を検出しています。物体の種類や操作した人物のログも記録し、必要に応じて使用者に通知を行うことで、迅速な対応を可能にします。将来的には、使用者のスケジュールと連携し、忘れそうな物を事前に予測・伝達する機能，使用者にわかりやすく伝える機能の実現も目指してます。また、この技術は介護や防犯など、他分野への応用も期待されます。

## 携帯端末を用いたインタラクションシステム
本研究では、スマートフォンなどの携帯端末を使って知能化空間内の機器と直感的にやり取りできるインタラクションシステムを提案しています。ユーザはスマートフォンのカメラを通して機器を撮影すると、機器に対応する操作画面が表示されてそのまま操作することができます。これまで提案されていた R-Fii というシステムでは、物体を操作するために事前に学習させたデータが必要であり、同種類の物体が複数存在する場合には区別が難しいという課題がありました。

そこで本システムでは、物体認識に事前学習なしで使える最新のモデル「YOLO-World」を導入し、スマートフォンのカメラの位置・向き（姿勢）情報を活用することで、同じ種類の物体を正確に見分けられる仕組みを実現しました。

{% capture col1 %}
{%
  include figure.html
  image="/images/ispace/10_mobile1.png"
  caption="インタラクションシステム概要"
  width="80%"
%}
{% endcapture %}
{% capture col2 %}
{%
  include figure.html
  image="/images/ispace/11_mobile2.png"
  caption="インタラクションシステムの流れ"
  width="80%"
%}
{% endcapture %}

{%
  include cols.html
  col1=col1
  col2=col2
%}

{% include responsive-file.html type="video" url="/images/ispace/12_mobile3.mp4" caption="インタラクションシステムのデモ動画" width="70%" %}

## 家具再配置システム
本研究は、空間知能化の一環として、現在の状況に応じた室内の物品配置の最適化を目指すシステムの開発に焦点を当てています。空間内において人々が家具を使用する過程で、その位置がずれることがあります。ここでは、特に移動頻度の高い家具である椅子に着目し、リアルタイムで位置を修正するシステムの開発を目的としています。

{% include responsive-file.html type="video" url="/images/ispace/13_furniture.mp4" caption="椅子を移動させる様子" width="70%" %}

具体的な実現方法として、空間内に配置されたカメラを用いて椅子の位置を取得し、事前に設定された位置と比較することで、ズレが発生しているかを判断します。ズレが検出された場合、ロボットが椅子の現在位置の情報を受け取り、椅子を元の位置に戻します。
{% endcase %}
