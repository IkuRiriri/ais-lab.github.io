---
title: Ritsumei Real-World Robotic Metaverse (R-Metaverse)
author: Yuhi Nishikori
lang: jp
tags:
  - Robotics
  - Virtual Reality
---
# Ritsumei Real-World Robotic Metaverse (R-Metaverse)

{%
  include responsive-file.html
  type="image"
  url="/images/rmetaverse/R-Metaverse_Logo.png"
  caption=""
  width="80%"
%}

{% case site.lang %}
{% when 'en' %}
## Three Features
R-Metaverse has three key features:
1. **Remote Operation**

    Remote participants (robot users) can wear HMDs and operate telepresence robots remotely.
2. **Integration of Reality and CG (MR)**

    Through Mixed Reality (MR), users can not only view video from remote locations but also experience 3DCG overlays, creating a fusion of reality and computer graphics.
3. **On-site Interaction**

    People at the physical location (mobile users) can use smartphones to view the MR experience of users operating the telepresence robots, enabling interaction between on-site and remote participants.

{%
  include responsive-file.html
  type="image"
  url="/images/rmetaverse/R-Meta_overeview.png"
  caption="Overview of R-Metaverse"
  width="60%"
%}

## Research Background

In recent years, content using virtual spaces built on computers, known as metaverse, has gained attention. By using HMDs (Head-Mounted Displays), the metaverse enables users to experience virtual spaces with a sense of presence through virtual avatars, as if they were actually inside the virtual space. Furthermore, when this space is connected to a network, it allows people to interact as if they were talking in person, ignoring physical constraints of distance.

Due to the COVID-19 pandemic's impact on promoting remote work practices in businesses, an increase in metaverse-based services is anticipated in the future. However, experiencing 3D virtual spaces used in the metaverse requires significant costs. The costs mentioned here refer to the effort required to create spaces, the computation needed to render spaces, and the collision detection calculations necessary when experiencing these spaces. Additionally, the adoption rate of VR goggles is less than 10%, and there's a limitation where experiences are confined only to users wearing HMDs. To address these issues, we propose "Ritsumei Real-World Robotic Metaverse (R-Metaverse)," a new form of metaverse that utilizes remotely operated robots and real physical spaces.

## System Configuration

{% capture col1 %}

{%
  include responsive-file.html
  type="image"
  url="/images/rmetaverse/data_flow.png"
  caption="System Overview of R-Metaverse"
  width="100%"
%}

{% endcapture %}

{% capture col2 %}
In R-Metaverse, ROS2 is used for data transmission and processing between devices. Unity is used to implement the Mixed Reality (MR) experience.

Using Visual SLAM technology called ORBSLAM2, images obtained from smartphones or robots are processed in real-time to estimate the position and orientation of each camera in the physical space. The position and orientation data obtained from ORBSLAM2 is utilized to implement MR functionality.
{% endcapture %}

{%
  include cols.html
  col1=col1
  col2=col2
%}

### Telepresence Robot

{% capture col1 %}

{%
  include responsive-file.html
  type="image"
  url="/images/rmetaverse/TelepresenceRobot.jpg"
  caption="Telepresence Robot"
  width="100%"
%}

{% endcapture %}

{% capture col2 %}
The telepresence robot is a palm-sized small robot measuring 80mm in width, 125mm in depth, 72mm in height, and weighing 450g. This allows users to experience moving through the real world in a miniaturized body scaled to the robot's size, enabling them to enjoy experiences in spaces that are normally inaccessible, such as under floors or in ceiling cavities.
{% endcapture %}

{%
  include cols.html
  col1=col1
  col2=col2
%}

## System

In online communication, the degree to which one feels "the other person is there, the other person is nearby" is called social presence. Social presence is higher in media that can convey non-verbal information such as facial expressions and gestures, leading to better communication. Therefore, in today's increasing demand for online communication, it is important to develop systems that can convey non-verbal information with awareness of social presence to build good relationships.

### Mobile User's Facial Expression Confirmation System

This system allows robot users who remotely operate robots to check the facial expressions of mobile users participating via smartphones. This enables robot users to feel closer to mobile users who are actually at a distance. The facial expressions are displayed at the top of the robot user's view screen.

{% capture col1 %}

{% 
  include responsive-file.html 
  type="image" 
  url="/images/rmetaverse/hmd_f.png" 
  caption="Robot User During Experiment" 
  width="80%"
%}

{% endcapture %}

{% capture col2 %}

{% 
  include responsive-file.html
  type="video" 
  url="/images/rmetaverse/hmd_app_del.mp4" 
  caption="Robot User's Perspective During Experiment" 
  width="80%" 
%}

{% endcapture %}

{%
  include cols.html
  col1=col1
  col2=col2
%}

### Robot User Avatar Confirmation System

This system allows mobile users participating via smartphones to see the gestures of robot users who are remotely operating robots, such as head and hand movements. This enables mobile users to feel closer to robot users who are actually remote. When a mobile user points their smartphone at the robot, an avatar synchronized with the robot user's movements is displayed. Additionally, in the lower left corner of the screen, users can see how their own facial expressions are being captured (Mobile User's Facial Expression Confirmation System).

{% capture col1 %}

{% 
  include responsive-file.html 
  type="image" 
  url="/images/rmetaverse/mobile_f.png" 
  caption="Mobile User During Experiment" 
  width="80%"
%}

{% endcapture %}

{% capture col2 %}

{% 
  include responsive-file.html
  type="video" 
  url="/images/rmetaverse/android_app.mp4" 
  caption="Mobile User's App Screen During Experiment" 
  width="80%" 
%}

{% endcapture %}

{%
  include cols.html
  col1=col1
  col2=col2
%}

{% when 'jp' %}

## 3つの特徴
R-Metaverseには3つの特徴があります。
1. **遠隔操作**

    遠隔の参加者(ロボットユーザ)がHMDを被り、テレプレゼンスロボットの遠隔操作が可能です。
2. **現実とCGの融合表現(MR)**

    MRにより、遠隔地の映像を確認できるだけでなく、3DCGが映り、現実とCGの融合表現が体験可能です。
3. **現地で交流**

    テレプレゼンスロボットを操作しているユーザが体験しているMRを現地の人間(モバイルユーザ)がスマートフォンを用いて確認することができ、現地の参加者も遠隔の参加者との交流が可能です。

{%
  include responsive-file.html
  type="image"
  url="/images/rmetaverse/R-Meta_overeview.png"
  caption="R-Metaverseの概要"
  width="60%"
%}

## 研究背景

近年、メタバースと呼ばれるコンピュータ上に構築された仮想空間を用いたコンテンツが注目されています。メタバースはHMDを用いることで、仮想のアバタによって自身が仮想空間の中に存在しているかのような臨場感とともに空間内の体験が可能です。さらに、この空間がネットワークと繋がることで、物理的な制約を無視し、離れている人とその場で話しているかのように交流することが可能です。

新型コロナウイルス感染拡大の影響により企業の業務形態のリモート化が促進されたことで、今後メタバースを利用したサービスが増加することが予想されます。 しかし、メタバースに用いる3次元仮想空間を体験するには大きなコストが必要となります。ここで述べるコストとは、空間の制作にかかる手間や、空間の描画に必要な計算、空間を体験する際に必要な当たり判定の計算などを指します。また、VRゴーグルの普及率は 1 割未満であり、体験がHMDを付けているユーザの間で完結してしまうといった欠点があります。そこで我々は問題解決のため遠隔操作ロボットと現実空間を利用した新しいメタバースの形である「Ritsumei Real-World Robotic Metaverse(R-Metaverse)」を提案します。

## システム構成

{% capture col1 %}

{%
  include responsive-file.html
  type="image"
  url="/images/rmetaverse/data_flow.png"
  caption="R-Metaverseのシステム概要"
  width="100%"
%}

{% endcapture %}

{% capture col2 %}
R-Metaverseでは、ROS2を使用して各デバイスのデータの送信や処理を行っています。また、Unityを使用してMRを実装しています。

Visual SLAMであるORBSLAM2により、スマートフォン、またロボットから得られた画像をリアルタイムで処理し、それぞれのカメラが現実空間のどの位置・姿勢であるかを推定しています。ORBSLAM2から得られた位置・姿勢を活用してMRを実装しています。
{% endcapture %}

{%
  include cols.html
  col1=col1
  col2=col2
%}

### テレプレゼンスロボット

{% capture col1 %}

{%
  include responsive-file.html
  type="image"
  url="/images/rmetaverse/TelepresenceRobot.jpg"
  caption="テレプレゼンスロボット"
  width="100%"
%}

{% endcapture %}

{% capture col2 %}
テレプレゼンスロボットは幅80mm、奥行125mm、高さ72mm、重さ450gの手のひらサイズの小さなロボットです。そのためロボットのスケールに縮小された体で現実世界を移動する感覚を体験でき、床下や天井裏など、普段立ち入ることができない空間を用いた体験を楽しむことができます。
{% endcapture %}

{%
  include cols.html
  col1=col1
  col2=col2
%}

## システム

オンラインでのコミュニケーションにおいて、「相手がそこにいる、相手が近くにいる」と感じる度合いをソーシャルプレゼンスといいます。ソーシャルプレゼンスは、表情や仕草などの非言語情報を伝えられるメディアほど高く、良好なコミュニケーションに繋がります。そのため、近年のオンラインでのコミュニケーションの需要が増加する状況の中で、良好な関係を構築するためには、ソーシャルプレゼンスを意識し、非言語情報を伝えられるシステムを開発することが重要です。

### モバイルユーザの表情確認システム

このシステムは、遠隔でロボットを操作するロボットユーザが、スマートフォンを用いて参加するモバイルユーザの表情を確認することが可能なシステムです。これによって、ロボットユーザは実際には遠隔にいるモバイルユーザをより近くにいると感じることができます。ロボットユーザの視点の画面上部に表情が映し出されます。

{% capture col1 %}

{% 
  include responsive-file.html 
  type="image" 
  url="/images/rmetaverse/hmd_f.png" 
  caption="ロボットユーザの実験の様子" 
  width="80%"
%}

{% endcapture %}

{% capture col2 %}

{% 
  include responsive-file.html
  type="video" 
  url="/images/rmetaverse/hmd_app_del.mp4" 
  caption="ロボットユーザの実験中の視点" 
  width="80%" 
%}

{% endcapture %}

{%
  include cols.html
  col1=col1
  col2=col2
%}

### ロボットユーザのアバタ確認システム

このシステムは、スマートフォンを用いて参加するモバイルユーザが、遠隔でロボットを操作するロボットユーザの頭や両手の動きといったジェスチャーを確認することが可能なシステムです。これによって、モバイルユーザは実際には遠隔にいるロボットユーザをより近くにいると感じることができます。モバイルユーザがロボットにスマホを向けたとき、ロボットユーザの動きが同期したアバタが映し出されます。また、画面左下には自身の表情がどのように映っているか表示されています(モバイルユーザの表情確認システム)。

{% capture col1 %}

{% 
  include responsive-file.html 
  type="image" 
  url="/images/rmetaverse/mobile_f.png" 
  caption="モバイルユーザの実験中の様子" 
  width="80%"
%}

{% endcapture %}

{% capture col2 %}

{% 
  include responsive-file.html
  type="video" 
  url="/images/rmetaverse/android_app.mp4" 
  caption="モバイルユーザの実験中のアプリ画面" 
  width="80%" 
%}

{% endcapture %}

{%
  include cols.html
  col1=col1
  col2=col2
%}
{% endcase %}