---
title: Road Weeding Robot (R4)
author: Yuki Matsushita
lang: jp
tags:
  - Robotics
---

{% case site.lang %}
{% when 'en' %}
# Road Weeding Robot (R4)

## Background
Currently in Japan, the aging population and the decline in the labor force have made it increasingly difficult to allocate sufficient manpower for infrastructure maintenance tasks, such as weeding along roads, in parks, and on riverbanks. Despite this, most weeding operations still rely heavily on manual labor. These tasks are especially demanding for workers, who must often operate under intense heat or in close proximity to busy roads. Moreover, due to the narrow sidewalks and shoulders typical of Japanese roads, the use of conventional large-scale weeding machines is often impractical.

In response to these challenges, this study focuses on the development of a compact robot capable of autonomously removing weeds along roadsides. By integrating robotics with computer vision techniques, we aim to enable safe and efficient weeding operations.

{% include responsive-file.html type="video" url="/images/r4/demo.mp4" caption="Weeding along the roadside" width="70%" %}

## Autonomous Weeding Robot R4
{% capture col1 %}
In this research, we are developing the autonomous mobile weeding robot R4 (Ritsumeikan Road-weed Removal Robot).

The robot's width is designed to be within 1m, allowing it to fit between the roadside white line and the sidewalk. This enables operation even on narrow shoulders without disrupting vehicle traffic. For the weeding mechanism, we have adopted a physical cutting system with a dedicated motor mounted on the robot. Since roadside weeds are not uniformly distributed, and the distance between the robot and weeds may vary, we have incorporated an adjustable positioning mechanism for the cutting blade.
{% endcapture %}
{% capture col2 %}
{%
  include figure.html
  image="/images/r4/r4.png"
  caption="Appearance of R4"
  width="80%"
%}
{% endcapture %}
{%
  include cols.html
  col1=col1
  col2=col2
%}

## Autonomous Navigation 
For autonomous navigation, the robot utilizes visual cues such as road markings and boundary lines. When white lines are present, they serve as the primary reference, as they clearly delineate the shoulder from the roadway. In the absence of white lines or when visibility is low, the robot relies on the road boundary to determine its path.

To recognize road boundaries, a segmentation-based approach is employed to identify the road area from camera images. Autonomous movement is achieved by maintaining a constant distance from the edge of the detected road region.

{% capture col1 %}
{% include responsive-file.html type="video" url="/images/r4/auto_nav.mp4" caption="Navigation from the robot’s perspective (Red: Road boundary, Green: Generated path)" width="70%" %}
{% endcapture %}

{% capture col2 %}
{% include responsive-file.html type="video" url="/images/r4/auto_move.MP4" caption="Autonomous navigation" width="70%" %}
{% endcapture %}

{%
  include cols.html
  col1=col1
  col2=col2
%}

## Weeding Function

### Weed Detection

To accurately detect roadside weeds, this study employs machine learning techniques. A custom weed dataset was created using images captured from a lateral viewpoint that closely resembles the R4’s perspective during operation. By training the model on this dataset, weed detection accuracy during real-world R4 operation is significantly improved compared to models trained on conventional top-down imagery.

### Weeding Mechanism

Once weeds are detected, a weeding mechanism mounted on the side of R4 is used to physically remove them. An RGBD camera measures the distance between R4 and the weed at the time of detection, and the position of the weeding device is adjusted accordingly. This allows R4 to effectively remove weeds even when they are located farther from its base.

{% include responsive-file.html type="video" url="/images/r4/demo2_combine.mp4" caption="Left: Weed detection, Right: Weeding operation" width="70%" %}

{% when 'jp' %}
# 道路除草ロボット（R4）

## 研究背景
現在、日本では高齢化と労働人口の減少により、道路、公園、河川敷などのインフラ維持管理に必要な人員確保が年々困難になっています。特に除草作業は人力に大きく依存しており、炎天下や交通量の多い道路脇での作業は作業員にとって非常に過酷な状況となっています。また、日本の道路は歩道や路肩が狭いため、従来の大型除草機の導入が困難なケースが多く存在します。

このような背景から、本研究では道路脇を自律移動しながら除草作業を行う小型ロボットの開発に取り組んでいます。ロボティクスと画像処理技術を組み合わせることで、効率的で安全な除草作業の実現を目指しています。

{% include responsive-file.html type="video" url="/images/r4/demo.mp4" caption="道路脇の除草の様子" width="70%" %}

## 自律除草ロボット R4
{% capture col1 %}
本研究では自律移動除草ロボットR4 (Ritsumeikan Road-weed Removal Robot)を開発しています。

ロボットの横幅は、道路脇の白線から歩道側に収まるよう1m以内に設計されています。これにより、狭い路肩でも車両の交通を妨げることなく作業が可能となります。除草機構には、物理的に雑草を刈り取る方式を採用し、ロボットに除草用のモータを搭載してます。道路脇の雑草は一様に分布しているわけではなく、ロボットと雑草の距離が変動する可能性があるため、除草刃の位置を調整可能な機構を設けています。
{% endcapture %}
{% capture col2 %}
{%
  include figure.html
  image="/images/r4/r4.png"
  caption="R4の外観"
  width="80%"
%}
{% endcapture %}
{%
  include cols.html
  col1=col1
  col2=col2
%}

## 自律移動
自律移動には、道路上の目印として白線と道路の境界線を利用します。白線は路肩と車道を明確に区別できるため、白線が存在する場合はこれを主な目印とします。白線がない場合や視認性が低下している場合は、道路の境界線を用いて移動経路を決定します。

道路境界の認識にはセグメンテーションを利用し、カメラ画像から道路領域を識別します。道路の端から一定の距離を維持するように動作させることで、自律移動を実現しています。

{% capture col1 %}
{% include responsive-file.html type="video" url="/images/r4/auto_nav.mp4" caption="ロボット視点の移動の様子
（赤：道路境界、緑：生成経路）" width="70%" %}
{% endcapture %}

{% capture col2 %}
{% include responsive-file.html type="video" url="/images/r4/auto_move.MP4" caption="自律移動の様子" width="70%" %}
{% endcapture %}

{%
  include cols.html
  col1=col1
  col2=col2
%}

## 除草機能
### 雑草検出
道路脇の雑草を正確に検出するため、機械学習を利用しています。本研究では，R4の視点に近い横からの視点で撮影された画像に特化した独自の雑草データセットを作成し、モデルに学習させています。これにより、一般的な上空からの視点にもとづくモデルに比べ、R4動作時の雑草認識精度が向上しています。

### 除草機構
検出された雑草に対しては、R4側面に取り付けられた除草機を用いて処理を行います。雑草検出時にRGBDカメラで、R4から雑草までの距離を計測し、それに応じて除草機の位置を調整します。これにより、雑草がR4から離れている場合でも除草することが可能になります。
{% include responsive-file.html type="video" url="/images/r4/demo2_combine.mp4" caption="左：雑草検出の様子、右：除草の様子" width="70%" %}

{% endcase %}